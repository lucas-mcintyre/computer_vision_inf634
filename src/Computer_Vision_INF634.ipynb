{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3FVKymeUKpf"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!cp -r gdrive/MyDrive/clean-dirty-garbage-containers-V6.1 ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_9_H7vLbVvF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqPsiocv0FuI"
      },
      "outputs": [],
      "source": [
        "! pip install torch-lr-finder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBcQJqJjUT_8"
      },
      "outputs": [],
      "source": [
        "from data import get_dataloaders, MontevideoDirtyContainerDataset\n",
        "from models import load_model, perform_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7smAJ8iXu7Q"
      },
      "outputs": [],
      "source": [
        "model = load_model(\"resnet18\", [1024,256,32], 0.4, freeze=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehhlf15ufvlC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "train, val, test = get_dataloaders(16,\"clean-dirty-garbage-containers-V6.1\",\"clean-dirty-garbage-containers-V6.1/clean-dirty-garbage-containers/clean-dirty-metadata.csv\", use_augmentation=False)\n",
        "criterion = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "model.to(device)\n",
        "out1 = perform_training(model, train, val, criterion, optimizer, 10, device, use_scheduler=True, scheduler_patience=2, auto_lr_find=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from models import unfreeze_model\n",
        "\n",
        "unfreeze_model(model)"
      ],
      "metadata": {
        "id": "ejuXqBKZlc69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, val, test = get_dataloaders(16,\"clean-dirty-garbage-containers-V6.1\",\"clean-dirty-garbage-containers-V6.1/clean-dirty-garbage-containers/clean-dirty-metadata.csv\", use_augmentation=True)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
        "out2 = perform_training(model, train, val, criterion, optimizer, 20, device, use_scheduler=True, scheduler_patience=2, auto_lr_find=False)"
      ],
      "metadata": {
        "id": "HXOEXKiNk3K8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = out1[0] + out2[0]\n",
        "val_losses = out1[1] + out2[1]"
      ],
      "metadata": {
        "id": "jwjSi_AG2kl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(train_losses)\n",
        "plt.plot(val_losses)\n",
        "# plt.savefig(\"gdrive/MyDrive/results/[XYXYXY].jpg\")"
      ],
      "metadata": {
        "id": "Fw-dqMlYBErK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuHiRcv6ZMea"
      },
      "outputs": [],
      "source": [
        "from models import perform_testing\n",
        "\n",
        "preds, labels = perform_testing(model.to(device), test, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYLbmiENaA97"
      },
      "outputs": [],
      "source": [
        "from evaluation import evaluate_predictions, plot_false_predictions\n",
        "\n",
        "evaluate_predictions(preds, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAKMTKzRbDG4"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "test_set = MontevideoDirtyContainerDataset(\"clean-dirty-garbage-containers-V6.1/clean-dirty-garbage-containers/clean-dirty-metadata.csv\",\"clean-dirty-garbage-containers-V6.1\",transform,\"test\")\n",
        "\n",
        "plot_false_predictions(preds, labels, test_set, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detecting Garbage using Grad-CAMs"
      ],
      "metadata": {
        "id": "-Pq-POgH5PX2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqzNjkHswm-U"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import cv2\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from interpretation import plot_grad_cam\n",
        "\n",
        "plot_grad_cam(5, 5, model, test, device)"
      ],
      "metadata": {
        "id": "mWspbIl15pux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from models import save_model\n",
        "\n",
        "save_model(model, \"resnet18-0.925-1024-256-32\", \"/content/gdrive/MyDrive/models/\")"
      ],
      "metadata": {
        "id": "lK7ZUXIEAMY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation and Plots"
      ],
      "metadata": {
        "id": "SuS5imE4VQ7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!cp -r gdrive/MyDrive/clean-dirty-garbage-containers-V6.1 ."
      ],
      "metadata": {
        "id": "3oD81iS1VQUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "KcZ6ZEczVyth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-lr-finder"
      ],
      "metadata": {
        "id": "eRhp9Z4yV0MX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from data import get_dataloaders, MontevideoDirtyContainerDataset\n",
        "\n",
        "train, val, test = get_dataloaders(16,\"clean-dirty-garbage-containers-V6.1\",\"clean-dirty-garbage-containers-V6.1/clean-dirty-garbage-containers/clean-dirty-metadata.csv\", use_augmentation=False)"
      ],
      "metadata": {
        "id": "b6koCkHiV624"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from models import load_model_from_saved\n",
        "\n",
        "model = load_model_from_saved(\"efficientnet-b0\", [1024,256,32], 0.4, \"/content/gdrive/MyDrive/models/\", \"efficientb0-0.935-1024-256-32\", device)"
      ],
      "metadata": {
        "id": "YgEfWsNGIazn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from models import perform_testing\n",
        "\n",
        "preds, labels = perform_testing(model.to(device), test, device)"
      ],
      "metadata": {
        "id": "-bvLmLhhTYS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluation import evaluate_predictions, plot_false_predictions\n",
        "\n",
        "res = evaluate_predictions(preds, labels)"
      ],
      "metadata": {
        "id": "jaldk5T2TfIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "transform = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "test_set = MontevideoDirtyContainerDataset(\"clean-dirty-garbage-containers-V6.1/clean-dirty-garbage-containers/clean-dirty-metadata.csv\",\"clean-dirty-garbage-containers-V6.1\",transform,\"test\")\n",
        "\n",
        "fig = plot_false_predictions(preds, labels, test_set, device)\n",
        "# fig.savefig(\"/content/gdrive/MyDrive/results/[XYXYXY].jpg\", dpi=400)"
      ],
      "metadata": {
        "id": "7xuoKMUpThWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from interpretation import plot_predictions\n",
        "\n",
        "fig = plot_predictions(preds, labels, test_set, 6, 5, model, device)\n",
        "# fig.savefig(\"/content/gdrive/MyDrive/results/[XYXYXY].jpg\", dpi=400)"
      ],
      "metadata": {
        "id": "FFPhCizbRMK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning the streets using Image Inpainting"
      ],
      "metadata": {
        "id": "w2N-b44B7uAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "it = iter(test)\n",
        "dirty_list = []\n",
        "for i in range(40):\n",
        "  img, label, _  = next(it)\n",
        "  for j in range(len(label)):\n",
        "    if label[j] == 1:\n",
        "      dirty_list.append(img[j])"
      ],
      "metadata": {
        "id": "0AH5pY0p28Yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "from interpretation import ResNet_CAM\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "inv_norm = transforms.Compose([transforms.Normalize(mean=[0., 0., 0.],\n",
        "                                                        std=[1 / 0.229, 1 / 0.224, 1 / 0.225]),\n",
        "                                   transforms.Normalize(mean=[-0.485, -0.456, -0.406],\n",
        "                                                        std=[1., 1., 1.]), ])\n",
        "def get_inpaint_images(net, img, threshold):\n",
        "  net.eval()\n",
        "  pred = net(img)\n",
        "  pred[:, pred.argmax(dim=1)].backward()\n",
        "  gradients = net.get_activations_gradient()\n",
        "  pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
        "  activations = net.get_activations(img).detach()\n",
        "  for i in range(activations.size(1)):\n",
        "      activations[:, i, :, :] *= pooled_gradients[i]\n",
        "  heatmap = torch.mean(activations, dim=1).squeeze()\n",
        "  heatmap = np.maximum(heatmap, 0)\n",
        "  heatmap /= torch.max(heatmap)\n",
        "  \n",
        "  heatmap = cv2.resize(heatmap.numpy(), (img.shape[2], img.shape[3]))\n",
        "  heatmap = torch.tensor(heatmap)\n",
        "\n",
        "  img1 = torch.where(heatmap>threshold, 0, img)\n",
        "  img_mask = torch.where(heatmap>threshold, 255.0, torch.zeros(img.size()))\n",
        "  torchvision.utils.save_image(inv_norm(img1), \"img_to_inpaint\" + str(layer_k) + \".jpg\")\n",
        "  torchvision.utils.save_image(img_mask, \"mask\" + str(layer_k) + \".jpg\")\n",
        "\n",
        "layer_k = 6\n",
        "threshold = 0.2\n",
        "\n",
        "model.train()\n",
        "baseline_cam_net = ResNet_CAM(model, layer_k)\n",
        "baseline_cam_net.to(\"cpu\")\n",
        "\n",
        "i = 10\n",
        "img = dirty_list[i][None]\n",
        "get_inpaint_images(baseline_cam_net, img, threshold)\n",
        "\n",
        "img_to_inpaint = cv2.imread(f\"./img_to_inpaint{layer_k}.jpg\")\n",
        "mask = cv2.imread(f'./mask{layer_k}.jpg',0)\n",
        "\n",
        "dst = cv2.inpaint(img_to_inpaint,mask,3,cv2.INPAINT_NS)\n",
        "\n",
        "cv2_imshow((inv_norm(img)*256)[0].permute(1,2,0).numpy())\n",
        "cv2_imshow(dst)\n",
        "# cv2.imwrite(f\"/content/gdrive/MyDrive/results/ex{i}-dirty.jpg\", (inv_norm(img)*256)[0].permute(1,2,0).numpy())\n",
        "# cv2.imwrite(f\"/content/gdrive/MyDrive/results/ex{i}-clean.jpg\", dst)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "UGNwxWjVxmnP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}